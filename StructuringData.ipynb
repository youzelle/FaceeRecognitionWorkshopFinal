{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates array of file paths\n",
    "female = glob('./data/crop/female_crop/*.png')\n",
    "male = glob('./data/crop/male_crop/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = female + male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(path[0])\n",
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Dataframe of image sizez\n",
    "images = {'path': [path[50],path[1],path[1000],path[2503],path[2021],path[2051]],\n",
    "        'size': [273, 54, 182, 81, 182, 122]}\n",
    "df = pd.DataFrame(data=images, columns=['path', 'size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['size'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from analysis resize all imgaes to 100 x 100\n",
    "# remove images <= 90\n",
    "df_new = df[df['size'] > 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new\n",
    "# What is the balance of female vs male images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize to make larger & flatten\n",
    "gray_0 = cv2.cvtColor(cv2.imread('./data/crop/female_crop/female_1248.png'), cv2.COLOR_BGR2GRAY)\n",
    "gray_re_0 = cv2.resize(gray_0,(140,140),cv2.INTER_CUBIC) # ENLARGE\n",
    "flatten_0 = gray_re_0.flatten()\n",
    "\n",
    "print('original size: ', gray_0.size)\n",
    "print('original shaoe: ', gray_0.shape)\n",
    "print(gray_0)\n",
    "\n",
    "print('____________________________________')\n",
    "\n",
    "print('re-size: ', gray_re_0.size)\n",
    "\n",
    "print('____________________________________')\n",
    "\n",
    "\n",
    "print('flattened size: ', flatten_0.size)\n",
    "print('flattened shape: ', gray_0.shape)\n",
    "print(flatten_0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get size of all images\n",
    "def getSize(path):\n",
    "    img = Image.open(path)\n",
    "    return img.size[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Dataframe of the image paths\n",
    "df = pd.DataFrame(data=path, columns=['path'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  apply getSize function to dataframe  \n",
    "# print result\n",
    "df['size'] = df['path'].apply(getSize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a histogram to check spread of image sizes, start with a bin of 30\n",
    "df.describe()\n",
    "plt.hist(df['size'], bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a suitable size to resize the images \n",
    "\n",
    "# create a function and remove unwanted images\n",
    "df_new = df[df['size'] > 60]\n",
    "# assign results to a new dataframe  \n",
    "df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that returns the gender from each image path\n",
    "def gender(string):\n",
    "    try:\n",
    "\n",
    "        return string.split('_')[0].split('/')[-1]\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "# apply the method to the new dataframe, name the column 'gender'\n",
    "df['gender'] = df['path'].apply(gender)\n",
    "\n",
    "# print the new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a method to resize and flatten images\n",
    "def resize_img(path_to_resize):\n",
    "    try:\n",
    "\n",
    "        # step - 1: read image\n",
    "        img = cv2.imread(path_to_resize)\n",
    "        # step - 2: convert into grayscale\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        # step -3: resize into 100 x 100 array\n",
    "        size = gray.shape[0]\n",
    "        if size >= 100: #shrink\n",
    "            gray_re = cv2.resize(gray,(100,100),cv2.INTER_AREA) # SHRINK\n",
    "        else: # enlarge\n",
    "            gray_re = cv2.resize(gray,(100,100),cv2.INTER_CUBIC) # ENLARGE\n",
    "        # step -4: Flatten Image (1x10,000)\n",
    "        return gray_re.flatten()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "len(resize_img(path[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce a dataframe that show the gender of the images \n",
    "\n",
    "# as well as flattened pixel values in own columns\n",
    "\n",
    "df_new['gender'] = df_new['path'].apply(gender)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHAT HAPPENS WHEN YOU RUN THIS?\n",
    "# plt.imshow(df2.loc[0][1:].values.reshape(---,---).astype('int'),cmap='gray')\n",
    "\n",
    "# plt.title(\"Label: \"+df2.loc[0]['gender'])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# pickle.dump(df2,open('./data/dataframe_images_100_100.pickle','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
